{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPT1Ujbh9KrBHD6zfM2qO18",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeterSinoyiannis/Cyber-Guardian/blob/main/Cyber_Guardian_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EEE-ULIabNW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from torch.utils.data import DataLoader\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Load the pre-trained AlexNet model\n",
        "alexnet = models.alexnet(pretrained=True)\n",
        "\n",
        "# Freeze the weights of the pre-trained model\n",
        "for param in alexnet.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the last fully connected layer to match the number of pitch types in the dataset\n",
        "num_weapon_types = 2\n",
        "alexnet.classifier[6] = torch.nn.Linear(4096, num_weapon_types)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(alexnet.classifier.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Define the data transforms\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Load the data from Google Drive\n",
        "data_dir = '/content/gdrive/MyDrive/weaponsalexnet'\n",
        "image_datasets = {x: datasets.ImageFolder(data_dir + '/' + x, data_transforms[x]) for x in ['train', 'valid']}\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=4) for x in ['train', 'valid']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "# Train the model\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "train_accs = []\n",
        "valid_accs = []\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    for (inputs, labels) in dataloaders[\"train\"]:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = alexnet(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "    epoch_loss = running_loss / len(dataloaders[\"train\"])\n",
        "    epoch_acc = running_corrects.double() / len(image_datasets[\"train\"])\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accs.append(epoch_acc)\n",
        "    print('Epoch [%d], Training Loss: %.4f, Training Accuracy: %.4f' % (epoch+1, epoch_loss, epoch_acc))\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    all_labels = []\n",
        "    all_scores = []\n",
        "    with torch.no_grad():\n",
        "        for (inputs, labels) in dataloaders[\"valid\"]:\n",
        "            outputs = alexnet(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            all_labels.extend(labels.data.cpu().numpy())\n",
        "            all_scores.extend(torch.nn.functional.softmax(outputs, dim=1).data.cpu().numpy()[:, 1])\n",
        "    epoch_loss = running_loss / len(dataloaders[\"valid\"])\n",
        "    epoch_acc = running_corrects.double() / len(image_datasets[\"valid\"])\n",
        "    valid_losses.append(epoch_loss)\n",
        "    valid_accs.append(epoch_acc)\n",
        "    print('Epoch [%d], Validation Loss: %.4f, Validation Accuracy: %.4f' % (epoch+1, epoch_loss, epoch_acc))\n",
        "\n",
        "# Plot the learning curve\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(valid_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Learning Curve')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the ROC curve\n",
        "fpr, tpr, _ = roc_curve(all_labels, all_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.plot(fpr, tpr, label='ROC Curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FnWpz1gZaiuj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}